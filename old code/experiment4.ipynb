{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df8170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141b9079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 17:11:58.995 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.204 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/salahuddin/.local/lib/python3.8/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-05-12 17:11:59.205 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.205 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.206 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.206 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.208 Session state does not function when running a script without `streamlit run`\n",
      "2025-05-12 17:11:59.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.210 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.210 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:11:59.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LoanID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HasMortgage</th>\n",
       "      <th>HasDependents</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>HasCoSigner</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I38PQUQS96</td>\n",
       "      <td>56</td>\n",
       "      <td>85994</td>\n",
       "      <td>50587</td>\n",
       "      <td>520</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>15.23</td>\n",
       "      <td>36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPSK72WA7R</td>\n",
       "      <td>69</td>\n",
       "      <td>50432</td>\n",
       "      <td>124440</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4.81</td>\n",
       "      <td>60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1OZ6DPJ8Y</td>\n",
       "      <td>46</td>\n",
       "      <td>84208</td>\n",
       "      <td>129188</td>\n",
       "      <td>451</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21.17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Auto</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V2KKSFM3UN</td>\n",
       "      <td>32</td>\n",
       "      <td>31713</td>\n",
       "      <td>44799</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.07</td>\n",
       "      <td>24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>High School</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Business</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EY08JDHTZP</td>\n",
       "      <td>60</td>\n",
       "      <td>20437</td>\n",
       "      <td>9139</td>\n",
       "      <td>633</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6.51</td>\n",
       "      <td>48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Auto</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
       "0  I38PQUQS96   56   85994       50587          520              80   \n",
       "1  HPSK72WA7R   69   50432      124440          458              15   \n",
       "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
       "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
       "4  EY08JDHTZP   60   20437        9139          633               8   \n",
       "\n",
       "   NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
       "0               4         15.23        36      0.44   Bachelor's   \n",
       "1               1          4.81        60      0.68     Master's   \n",
       "2               3         21.17        24      0.31     Master's   \n",
       "3               3          7.07        24      0.23  High School   \n",
       "4               4          6.51        48      0.73   Bachelor's   \n",
       "\n",
       "  EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
       "0      Full-time      Divorced         Yes           Yes       Other   \n",
       "1      Full-time       Married          No            No       Other   \n",
       "2     Unemployed      Divorced         Yes           Yes        Auto   \n",
       "3      Full-time       Married          No            No    Business   \n",
       "4     Unemployed      Divorced          No           Yes        Auto   \n",
       "\n",
       "  HasCoSigner  Default  \n",
       "0         Yes        0  \n",
       "1         Yes        0  \n",
       "2          No        1  \n",
       "3          No        0  \n",
       "4          No        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pages.A_Explore_Preprocess_Dataset import load_dataset\n",
    "filepath = \"Loan_default.csv\"\n",
    "df = load_dataset(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b94f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 255347\n",
      "Number of features: 18\n",
      "Number of numeric features: 10\n",
      "Number of categorical features: 8\n",
      "% of rows with missing values: 0.00%\n",
      "Counts of 0 and 1: Default\n",
      "0    225694\n",
      "1     29653\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# print basic statistics about dataset - number of features, distribution of target variable\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(f\"Number of numeric features: {len(numeric_cols)}\")\n",
    "print(f\"Number of categorical features: {len(categorical_cols)}\")\n",
    "\n",
    "num_rows_with_missing = df.isnull().any(axis=1).sum()\n",
    "print(f\"% of rows with missing values: {num_rows_with_missing/df.shape[0] * 100:.2f}%\")\n",
    "\n",
    "print(\"Counts of 0 and 1:\", df['Default'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9262fc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "LoanID: 255347 unique values\n",
      "LoanID\n",
      "I38PQUQS96    1\n",
      "WGB0GD3150    1\n",
      "XATSFC5YHN    1\n",
      "CQXDW5VBAG    1\n",
      "6AIVUNAJG8    1\n",
      "             ..\n",
      "ZBK3GDL2LI    1\n",
      "SP7XY2LPYA    1\n",
      "Q2DO8ENMV1    1\n",
      "5EXD8N4MT4    1\n",
      "ZTH91CGL0B    1\n",
      "Name: count, Length: 255347, dtype: int64\n",
      "\n",
      "Education: 4 unique values\n",
      "Education\n",
      "Bachelor's     64366\n",
      "High School    63903\n",
      "Master's       63541\n",
      "PhD            63537\n",
      "Name: count, dtype: int64\n",
      "\n",
      "EmploymentType: 4 unique values\n",
      "EmploymentType\n",
      "Part-time        64161\n",
      "Unemployed       63824\n",
      "Self-employed    63706\n",
      "Full-time        63656\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MaritalStatus: 3 unique values\n",
      "MaritalStatus\n",
      "Married     85302\n",
      "Divorced    85033\n",
      "Single      85012\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HasMortgage: 2 unique values\n",
      "HasMortgage\n",
      "Yes    127677\n",
      "No     127670\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HasDependents: 2 unique values\n",
      "HasDependents\n",
      "Yes    127742\n",
      "No     127605\n",
      "Name: count, dtype: int64\n",
      "\n",
      "LoanPurpose: 5 unique values\n",
      "LoanPurpose\n",
      "Business     51298\n",
      "Home         51286\n",
      "Education    51005\n",
      "Other        50914\n",
      "Auto         50844\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HasCoSigner: 2 unique values\n",
      "HasCoSigner\n",
      "Yes    127701\n",
      "No     127646\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(categorical_cols))\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48553f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"LoanID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc61d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 17:12:10.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:12:10.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:12:10.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:12:10.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:12:10.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-12 17:12:10.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from pages.A_Explore_Preprocess_Dataset import one_hot_encode_feature \n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "df = one_hot_encode_feature(df, categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3414db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed',\n",
      "       'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio', 'Default',\n",
      "       'Education_Bachelor's', 'Education_High School', 'Education_Master's',\n",
      "       'Education_PhD', 'EmploymentType_Full-time', 'EmploymentType_Part-time',\n",
      "       'EmploymentType_Self-employed', 'EmploymentType_Unemployed',\n",
      "       'MaritalStatus_Divorced', 'MaritalStatus_Married',\n",
      "       'MaritalStatus_Single', 'HasMortgage_No', 'HasMortgage_Yes',\n",
      "       'HasDependents_No', 'HasDependents_Yes', 'LoanPurpose_Auto',\n",
      "       'LoanPurpose_Business', 'LoanPurpose_Education', 'LoanPurpose_Home',\n",
      "       'LoanPurpose_Other', 'HasCoSigner_No', 'HasCoSigner_Yes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737e20d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, \n",
    "                             confusion_matrix, ConfusionMatrixDisplay)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a182a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22109/1590693432.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[num_cols] = scaler.transform(X_train[num_cols])\n",
      "/tmp/ipykernel_22109/1590693432.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test [num_cols] = scaler.transform(X_test [num_cols])\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "# -------- 1.1  Identify columns ----------\n",
    "num_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed',\n",
    "            'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']\n",
    "target   = 'Default'\n",
    "\n",
    "X = df.drop(columns=[target]).copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# -------- 1.2  Train / test split (stratified) ----------\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=seed)\n",
    "train_idx, test_idx = next(sss.split(X, y))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx].values, y.iloc[test_idx].values\n",
    "\n",
    "# -------- 1.3  Standard-scale numeric features ----------\n",
    "scaler = StandardScaler().fit(X_train[num_cols])\n",
    "X_train[num_cols] = scaler.transform(X_train[num_cols])\n",
    "X_test [num_cols] = scaler.transform(X_test [num_cols])\n",
    "\n",
    "# Good practice â€“ keep the scaler for future inference\n",
    "Path(\"artifacts\").mkdir(exist_ok=True)\n",
    "pd.to_pickle(scaler, \"artifacts/num_scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e32ba8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "# Convert pandas â†’ torch tensors\n",
    "X_train_t = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_t  = torch.tensor(X_test.values , dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train.reshape(-1,1), dtype=torch.float32)\n",
    "y_test_t  = torch.tensor(y_test .reshape(-1,1), dtype=torch.float32)\n",
    "\n",
    "# Full train dataset âžœ random split into train / val\n",
    "full_ds = TensorDataset(X_train_t, y_train_t)\n",
    "val_fraction = 0.15\n",
    "n_val  = int(len(full_ds) * val_fraction)\n",
    "n_train= len(full_ds) - n_val\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val], \n",
    "                                generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=1024, shuffle=True,  drop_last=True)\n",
    "val_dl   = DataLoader(val_ds  , batch_size=2048, shuffle=False, drop_last=False)\n",
    "test_dl  = DataLoader(TensorDataset(X_test_t, y_test_t),\n",
    "                      batch_size=2048, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4d8d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_weight = 7.611289098726919\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "pos_weight = torch.tensor([ len(y_train) / y_train.sum()  - 1])  # â‰ˆ7.6\n",
    "print(\"pos_weight =\", pos_weight.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6f368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salahuddin/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_in, 256), nn.ReLU(), nn.Dropout(0.20),\n",
    "            nn.Linear(256,128),   nn.ReLU(), nn.Dropout(0.20),\n",
    "            nn.Linear(128,64),    nn.ReLU(),\n",
    "            nn.Linear(64,1)       # logits\n",
    "        )\n",
    "    def forward(self, x): \n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP(X_train_t.shape[1]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       mode='min', factor=0.5,\n",
    "                                                       patience=2, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "182f5340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train_loss=1.0208  val_AUC=0.7516\n",
      "Epoch 02: train_loss=1.0194  val_AUC=0.7515\n",
      "Epoch 03: train_loss=1.0197  val_AUC=0.7515\n",
      "Epoch 04: train_loss=1.0187  val_AUC=0.7515\n",
      "Epoch 05: train_loss=1.0200  val_AUC=0.7514\n",
      "Epoch 06: train_loss=1.0194  val_AUC=0.7514\n",
      "Epoch 07: train_loss=1.0188  val_AUC=0.7514\n",
      "Epoch 08: train_loss=1.0184  val_AUC=0.7514\n",
      "Epoch 09: train_loss=1.0191  val_AUC=0.7514\n",
      "Epoch 10: train_loss=1.0196  val_AUC=0.7514\n",
      "Epoch 11: train_loss=1.0190  val_AUC=0.7514\n",
      "Epoch 12: train_loss=1.0194  val_AUC=0.7514\n",
      "Epoch 13: train_loss=1.0202  val_AUC=0.7514\n",
      "Epoch 14: train_loss=1.0188  val_AUC=0.7514\n",
      "Epoch 15: train_loss=1.0197  val_AUC=0.7514\n",
      "Epoch 16: train_loss=1.0192  val_AUC=0.7514\n",
      "Epoch 17: train_loss=1.0192  val_AUC=0.7514\n",
      "Epoch 18: train_loss=1.0195  val_AUC=0.7514\n",
      "Epoch 19: train_loss=1.0185  val_AUC=0.7514\n",
      "Epoch 20: train_loss=1.0195  val_AUC=0.7514\n",
      "Epoch 21: train_loss=1.0185  val_AUC=0.7514\n",
      "Epoch 22: train_loss=1.0189  val_AUC=0.7514\n",
      "Epoch 23: train_loss=1.0198  val_AUC=0.7514\n",
      "Epoch 24: train_loss=1.0188  val_AUC=0.7514\n",
      "Epoch 25: train_loss=1.0191  val_AUC=0.7514\n",
      "Epoch 26: train_loss=1.0187  val_AUC=0.7514\n",
      "Epoch 27: train_loss=1.0180  val_AUC=0.7514\n",
      "Epoch 28: train_loss=1.0189  val_AUC=0.7514\n",
      "Epoch 29: train_loss=1.0189  val_AUC=0.7514\n",
      "Epoch 30: train_loss=1.0185  val_AUC=0.7514\n",
      "Epoch 31: train_loss=1.0194  val_AUC=0.7514\n",
      "Epoch 32: train_loss=1.0192  val_AUC=0.7514\n",
      "Epoch 33: train_loss=1.0190  val_AUC=0.7514\n",
      "Epoch 34: train_loss=1.0185  val_AUC=0.7514\n",
      "Epoch 35: train_loss=1.0196  val_AUC=0.7514\n",
      "Epoch 36: train_loss=1.0197  val_AUC=0.7514\n",
      "Epoch 37: train_loss=1.0184  val_AUC=0.7514\n",
      "Epoch 38: train_loss=1.0193  val_AUC=0.7514\n",
      "Epoch 39: train_loss=1.0190  val_AUC=0.7514\n",
      "Epoch 40: train_loss=1.0192  val_AUC=0.7514\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "epochs          = 40\n",
    "best_auc        = 0\n",
    "patience        = 4\n",
    "epochs_no_improve= 0\n",
    "ckpt_path       = \"artifacts/mlp_best.pt\"\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(train_dl.dataset)\n",
    "    \n",
    "    # ---- Validate ----\n",
    "    model.eval()\n",
    "    y_val_pred = []\n",
    "    y_val_true = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            y_val_pred.append(torch.sigmoid(logits).cpu())\n",
    "            y_val_true.append(yb)\n",
    "    y_val_pred = torch.cat(y_val_pred).numpy().ravel()\n",
    "    y_val_true = torch.cat(y_val_true).numpy().ravel()\n",
    "    val_auc  = roc_auc_score(y_val_true, y_val_pred)\n",
    "    scheduler.step(-val_auc)  # scheduler expects \"min\"; invert sign\n",
    "    \n",
    "    print(f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_AUC={val_auc:.4f}\")\n",
    "    \n",
    "    # # ---- Early stopping ----\n",
    "    # if val_auc > best_auc + 1e-4:\n",
    "    #     best_auc = val_auc\n",
    "    #     epochs_no_improve = 0\n",
    "    #     torch.save(model.state_dict(), ckpt_path)\n",
    "    # else:\n",
    "    #     epochs_no_improve += 1\n",
    "    #     if epochs_no_improve >= patience:\n",
    "    #         print(\"ðŸ›‘ Early stopping\")\n",
    "    #         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee89faa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC  : 0.7593\n",
      "Test PR-AUC   : 0.3331\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "# reload the best weights\n",
    "# model.load_state_dict(torch.load(ckpt_path))\n",
    "model.eval()\n",
    "\n",
    "y_test_pred = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dl:\n",
    "        xb = xb.to(device)\n",
    "        y_test_pred.append(torch.sigmoid(model(xb)).cpu())\n",
    "y_test_pred = torch.cat(y_test_pred).numpy().ravel()\n",
    "\n",
    "roc  = roc_auc_score(y_test, y_test_pred)\n",
    "pr   = average_precision_score(y_test, y_test_pred)\n",
    "print(f\"Test ROC-AUC  : {roc:.4f}\")\n",
    "print(f\"Test PR-AUC   : {pr :.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cffeba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  (@ 0.50):  69.89 %\n",
      "Balanced Acc            :  69.13 %\n",
      "\n",
      "Best-F1 threshold     :  0.599\n",
      "Accuracy  (@ best F1) :  78.64 %\n",
      "F1-score (@ best F1)  :  37.30 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
    "                             precision_recall_curve, f1_score)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Plain accuracy at a chosen threshold (default 0.50)\n",
    "thr = 0.50\n",
    "y_pred_bin = (y_test_pred >= thr).astype(int)\n",
    "\n",
    "acc  = accuracy_score(y_test, y_pred_bin)\n",
    "bacc = balanced_accuracy_score(y_test, y_pred_bin)\n",
    "\n",
    "print(f\"Accuracy  (@ {thr:.2f}): {acc*100:6.2f} %\")\n",
    "print(f\"Balanced Acc            : {bacc*100:6.2f} %\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Find threshold that maximises F1 on *validation* data\n",
    "prec, rec, pr_thr = precision_recall_curve(y_val_true, y_val_pred)\n",
    "f1   = 2*prec*rec / (prec+rec + 1e-12)\n",
    "best = np.argmax(f1)\n",
    "best_thr = pr_thr[best]\n",
    "\n",
    "# Evaluate accuracy at that threshold on the test set\n",
    "y_pred_best = (y_test_pred >= best_thr).astype(int)\n",
    "acc_best  = accuracy_score(y_test, y_pred_best)\n",
    "f1_best   = f1_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest-F1 threshold     : {best_thr:6.3f}\")\n",
    "print(f\"Accuracy  (@ best F1) : {acc_best*100:6.2f} %\")\n",
    "print(f\"F1-score (@ best F1)  : {f1_best*100:6.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57939da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC : 0.7638\n",
      "Train PR-AUC  : 0.3327\n",
      "\n",
      "Accuracy  (@ 0.50):  70.34 %\n",
      "Balanced Acc            :  69.46 %\n",
      "\n",
      "Best-F1 threshold       :  0.624\n",
      "Accuracy  (@ best F1)   :  80.61 %\n",
      "F1-score (@ best F1)    :  37.52 %\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), ckpt_path)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_logits = model(\n",
    "        torch.tensor(X_train.values, dtype=torch.float32, device=device)\n",
    "    )\n",
    "train_pred = torch.sigmoid(train_logits).cpu().numpy().ravel()\n",
    "y_train_np = y_train  # pandas â†’ numpy\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Threshold-free metrics\n",
    "train_roc = roc_auc_score(y_train_np, train_pred)\n",
    "train_pr  = average_precision_score(y_train_np, train_pred)\n",
    "print(f\"Train ROC-AUC : {train_roc:.4f}\")\n",
    "print(f\"Train PR-AUC  : {train_pr :.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Accuracy metrics at threshold 0.50\n",
    "thr = 0.50\n",
    "y_train_bin = (train_pred >= thr).astype(int)\n",
    "\n",
    "acc  = accuracy_score(y_train_np, y_train_bin)\n",
    "bacc = balanced_accuracy_score(y_train_np, y_train_bin)\n",
    "print(f\"\\nAccuracy  (@ {thr:.2f}): {acc *100:6.2f} %\")\n",
    "print(f\"Balanced Acc            : {bacc*100:6.2f} %\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Accuracy & F1 at the threshold that maximises F1 on training data\n",
    "prec, rec, pr_thr = precision_recall_curve(y_train_np, train_pred)\n",
    "f1_scores = 2*prec*rec / (prec + rec + 1e-12)\n",
    "best_idx  = f1_scores.argmax()\n",
    "best_thr  = pr_thr[best_idx]\n",
    "\n",
    "y_train_best = (train_pred >= best_thr).astype(int)\n",
    "acc_best = accuracy_score(y_train_np, y_train_best)\n",
    "f1_best  = f1_score(y_train_np, y_train_best)\n",
    "\n",
    "print(f\"\\nBest-F1 threshold       : {best_thr:6.3f}\")\n",
    "print(f\"Accuracy  (@ best F1)   : {acc_best*100:6.2f} %\")\n",
    "print(f\"F1-score (@ best F1)    : {f1_best *100:6.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f43898e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy ROC-AUC : 0.5\n",
      "Dummy PR-AUC  : 0.11613471705502251\n",
      "Dummy Acc     : 88.38652829449775 %\n",
      "Dummy Bal Acc : 50.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             balanced_accuracy_score, accuracy_score)\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "y_dummy_prob = dummy.predict_proba(X_test)[:,1]\n",
    "y_dummy_bin  = dummy.predict(X_test)\n",
    "\n",
    "print(\"Dummy ROC-AUC :\", roc_auc_score(y_test, y_dummy_prob))   # 0.50\n",
    "print(\"Dummy PR-AUC  :\", average_precision_score(y_test, y_dummy_prob))  # â‰ˆ0.116\n",
    "print(\"Dummy Acc     :\", accuracy_score(y_test, y_dummy_bin)*100, \"%\")   # 88 %\n",
    "print(\"Dummy Bal Acc :\", balanced_accuracy_score(y_test, y_dummy_bin)*100, \"%\")  # 50 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e076656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e058312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 0.3839\n",
      "epoch 2: loss 0.3837\n",
      "epoch 3: loss 0.3831\n",
      "epoch 4: loss 0.3822\n",
      "epoch 5: loss 0.3813\n",
      "epoch 6: loss 0.3802\n",
      "epoch 7: loss 0.3792\n",
      "epoch 8: loss 0.3781\n",
      "epoch 9: loss 0.3771\n",
      "epoch 10: loss 0.3761\n",
      "epoch 11: loss 0.3751\n",
      "epoch 12: loss 0.3742\n",
      "epoch 13: loss 0.3733\n",
      "epoch 14: loss 0.3724\n",
      "epoch 15: loss 0.3715\n",
      "epoch 16: loss 0.3707\n",
      "epoch 17: loss 0.3699\n",
      "epoch 18: loss 0.3691\n",
      "epoch 19: loss 0.3684\n",
      "epoch 20: loss 0.3677\n",
      "epoch 21: loss 0.3670\n",
      "epoch 22: loss 0.3663\n",
      "epoch 23: loss 0.3657\n",
      "epoch 24: loss 0.3651\n",
      "epoch 25: loss 0.3645\n",
      "epoch 26: loss 0.3640\n",
      "epoch 27: loss 0.3634\n",
      "epoch 28: loss 0.3629\n",
      "epoch 29: loss 0.3624\n",
      "epoch 30: loss 0.3619\n"
     ]
    }
   ],
   "source": [
    "from pages.ANN import ANN\n",
    "\n",
    "net = ANN(input_size=X_train.shape[1], lr=1e-3)\n",
    "\n",
    "epochs = 30\n",
    "batch  = 1024\n",
    "X_train_np = X_train.values.astype(np.float32)   # or .to_numpy()\n",
    "y_train_np = y_train.copy()   # shape (n,) or (n,1)\n",
    "\n",
    "# use these NumPy arrays in the loop\n",
    "for ep in range(epochs):\n",
    "    perm = np.random.permutation(len(X_train_np))\n",
    "    for i in range(0, len(X_train_np), batch):\n",
    "        idx  = perm[i:i+batch]\n",
    "        xb   = X_train_np[idx]\n",
    "        yb   = y_train_np[idx]\n",
    "        loss = net.training_step(xb, yb)\n",
    "        losses.append(loss)\n",
    "    print(f\"epoch {ep+1}: loss {np.mean(losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8242e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ROC-AUC : 0.7125\n",
      "TRAIN PR-AUC  : 0.2567\n",
      "TEST  ROC-AUC : 0.7186\n",
      "TEST  PR-AUC  : 0.2628\n",
      "\n",
      "Accuracy   (@0.50) â€“  TRAIN: 88.4 %\n",
      "BalancedAcc(@0.50) â€“  TRAIN: 50.69 %\n",
      "Accuracy   (@0.50) â€“  TEST : 88.43 %\n",
      "BalancedAcc(@0.50) â€“  TEST : 50.68 %\n",
      "\n",
      "Best-F1 threshold       : 0.184\n",
      "Accuracy  (@ best F1) â€“ TRAIN: 77.59 %\n",
      "F1-score (@ best F1) â€“ TRAIN: 32.34 %\n",
      "Accuracy  (@ best F1) â€“ TEST : 77.36 %\n",
      "F1-score (@ best F1) â€“ TEST : 32.53 %\n"
     ]
    }
   ],
   "source": [
    "# %%  â”€â”€â”€ Metrics for TRAIN and TEST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             accuracy_score, balanced_accuracy_score,\n",
    "                             precision_recall_curve, f1_score)\n",
    "\n",
    "# â”€â”€ 1. Ensure you have NumPy arrays (replace with your own vars) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_train_np = X_train.values.astype(np.float32)   # or X_train_np already\n",
    "y_train_np = y_train.copy()          # shape (n,)\n",
    "X_test_np  = X_test.values.astype(np.float32)\n",
    "y_test_np  = y_test.copy()\n",
    "\n",
    "# â”€â”€ 2. Probabilities from the new network â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "net.training = False              # inference mode (no dropout)\n",
    "probs_train = net.predict_proba(X_train_np)   # shape (n,)\n",
    "probs_test  = net.predict_proba(X_test_np)\n",
    "\n",
    "# â”€â”€ 3. Threshold-free metrics (ROC-AUC, PR-AUC) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"TRAIN ROC-AUC :\", roc_auc_score(y_train_np, probs_train).round(4))\n",
    "print(\"TRAIN PR-AUC  :\", average_precision_score(y_train_np, probs_train).round(4))\n",
    "print(\"TEST  ROC-AUC :\", roc_auc_score(y_test_np , probs_test ).round(4))\n",
    "print(\"TEST  PR-AUC  :\", average_precision_score(y_test_np , probs_test ).round(4))\n",
    "\n",
    "# â”€â”€ 4. Accuracy & balanced accuracy at threshold = 0.50 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "thr = 0.50\n",
    "train_bin = (probs_train >= thr).astype(int)\n",
    "test_bin  = (probs_test  >= thr).astype(int)\n",
    "\n",
    "print(f\"\\nAccuracy   (@{thr:.2f}) â€“  TRAIN:\", (accuracy_score(y_train_np, train_bin)*100).round(2), \"%\")\n",
    "print(  \"BalancedAcc(@{:.2f}) â€“  TRAIN:\".format(thr), (balanced_accuracy_score(y_train_np, train_bin)*100).round(2), \"%\")\n",
    "print(  \"Accuracy   (@{:.2f}) â€“  TEST :\".format(thr), (accuracy_score(y_test_np , test_bin )*100).round(2), \"%\")\n",
    "print(  \"BalancedAcc(@{:.2f}) â€“  TEST :\".format(thr), (balanced_accuracy_score(y_test_np , test_bin )*100).round(2), \"%\")\n",
    "\n",
    "# â”€â”€ 5. Find threshold that maximises F1 on TRAIN, then apply to TEST â”€â”€â”€â”€\n",
    "prec, rec, thr_arr = precision_recall_curve(y_train_np, probs_train)\n",
    "f1_scores = 2*prec*rec / (prec + rec + 1e-12)\n",
    "best_idx  = f1_scores.argmax()\n",
    "best_thr  = thr_arr[best_idx]\n",
    "\n",
    "print(f\"\\nBest-F1 threshold       : {best_thr:.3f}\")\n",
    "\n",
    "train_best = (probs_train >= best_thr).astype(int)\n",
    "test_best  = (probs_test  >= best_thr).astype(int)\n",
    "\n",
    "print(\"Accuracy  (@ best F1) â€“ TRAIN:\", (accuracy_score(y_train_np, train_best)*100).round(2), \"%\")\n",
    "print(\"F1-score (@ best F1) â€“ TRAIN:\", (f1_score(y_train_np, train_best)*100).round(2), \"%\")\n",
    "print(\"Accuracy  (@ best F1) â€“ TEST :\", (accuracy_score(y_test_np , test_best )*100).round(2), \"%\")\n",
    "print(\"F1-score (@ best F1) â€“ TEST :\", (f1_score(y_test_np , test_best )*100).round(2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "thr = 0.5\n",
    "y_hat = (y_test_pred >= thr).astype(int)\n",
    "cm   = confusion_matrix(y_test, y_hat)\n",
    "ConfusionMatrixDisplay(cm, display_labels=[\"No Default\",\"Default\"]).plot();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
